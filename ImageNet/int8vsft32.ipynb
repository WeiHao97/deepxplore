{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "from tensorflow.python.framework.ops import enable_eager_execution\n",
    "#disable_eager_execution()\n",
    "enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "from tensorflow.keras.layers import Input\n",
    "import scipy.misc\n",
    "\n",
    "from configs import bcolors\n",
    "from utils import *\n",
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(features):\n",
    "    \"\"\"Preprocesses the given image.\n",
    "\n",
    "      Args:\n",
    "        image: `Tensor` representing an image of arbitrary size.\n",
    "\n",
    "      Returns:\n",
    "        A preprocessed image `Tensor` of range [0, 1].\n",
    "  \"\"\"\n",
    "    image = features[\"image\"]\n",
    "    image = tf.image.resize(image,[224,224])\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    image = tf.keras.applications.resnet.preprocess_input(image)\n",
    "    #image = center_crop(image, 224, 224, crop_proportion=0.875)   # Standard for ImageNet.\n",
    "    #image = tf.reshape(image, [224, 224, 3])\n",
    "    #image = tf.clip_by_value(image, 0., 1.)\n",
    "    \n",
    "    features[\"image\"] = image\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50\n",
    "tfds_dataset2, tfds_info  = tfds.load(name='imagenet2012_subset', split='validation[-20%:]', with_info=True,\n",
    "                                     data_dir='/local/rcs/wei/image_net/')\n",
    "#tf.compat.v1.data.make_one_shot_iterator(tfds_dataset1).get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs = tfds.show_examples(tfds_dataset2, tfds_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = tfds_dataset2.map(preprocess_image).batch(BATCH_SIZE).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 224 ,224\n",
    "input_shape = (img_rows, img_cols, 3)\n",
    "model_ = ResNet50(input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_model = tfmot.quantization.keras.quantize_model(model_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(input_tensor = q_model.get_layer('input_1').input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"./original_model.h5\")\n",
    "q_model.load_weights(\"./q_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract():\n",
    "    for i, features in enumerate(val_ds):\n",
    "        image = np.expand_dims(features[\"image\"].numpy()[0], axis=0)\n",
    "        label = features[\"label\"].numpy()[0]\n",
    "        logits_1 = model(image).numpy()\n",
    "        logits_2 = q_model(image).numpy()\n",
    "        predict_1 = tf.argmax(logits_1, axis=-1).numpy()\n",
    "        predict_2 = tf.argmax(logits_2, axis=-1).numpy()\n",
    "        break\n",
    "    return image,label,logits_1,logits_2,predict_1,predict_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "__iter__() is only supported inside of tf.function or when eager execution is enabled.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-25f7047d6db2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlogits_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlogits_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredict_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredict_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-21c7b955afc3>\u001b[0m in \u001b[0;36mextract\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mlogits_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    415\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n\u001b[0m\u001b[1;32m    418\u001b[0m                          \"or when eager execution is enabled.\")\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: __iter__() is only supported inside of tf.function or when eager execution is enabled."
     ]
    }
   ],
   "source": [
    "image,label,logits_1,logits_2,predict_1,predict_2 = extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-0e1d8eee6cc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpil_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_to_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpil_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "pil_img = tf.keras.preprocessing.image.array_to_img(image[0,:,:,:])\n",
    "from IPython.display import Image\n",
    "display(pil_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.applications.resnet.decode_predictions(logits_1, top=5)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.applications.resnet.decode_predictions(logits_2, top=5)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./trailer_truck.npy\",image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate adverserial example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.load(\"./trailer_truck.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_diff = 10\n",
    "orig_label = 867\n",
    "grad_iterations = 20\n",
    "transformation = 'light'\n",
    "step = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "different\n",
      "565\n",
      "867\n",
      "[('n03393912', 'freight_car', 0.47857615), ('n04467665', 'trailer_truck', 0.4567812), ('n03417042', 'garbage_truck', 0.017796256), ('n04310018', 'steam_locomotive', 0.014601685), ('n03796401', 'moving_van', 0.013246967)]\n",
      "[('n04467665', 'trailer_truck', 0.640401), ('n03393912', 'freight_car', 0.200086), ('n03417042', 'garbage_truck', 0.07589043), ('n03796401', 'moving_van', 0.038500518), ('n04310018', 'steam_locomotive', 0.013253607)]\n"
     ]
    }
   ],
   "source": [
    "orig_img = image.copy()\n",
    "for iters in range(0,grad_iterations):\n",
    "    input_image = tf.convert_to_tensor(orig_img)\n",
    "\n",
    "    with tf.GradientTape() as g:\n",
    "        g.watch(input_image)\n",
    "        loss1 = K.mean(model(input_image)[..., orig_label])\n",
    "        loss2 = K.mean(q_model(input_image)[..., orig_label])\n",
    "        final_loss = K.mean(loss1 - weight_diff*loss2)\n",
    "        #A = argmin L(F(image + A) , y) - c* L(f(image + A) , y_1) \n",
    "\n",
    "    grads = normalize(g.gradient(final_loss, input_image)[0])\n",
    "\n",
    "    #grads_value = iterate([image])[0]\n",
    "    if transformation == 'light':\n",
    "        grads = constraint_light(grads)  # constraint the gradients value\n",
    "    elif transformation == 'occl':\n",
    "        grads = constraint_occl(grads, start_point,occlusion_size)  # constraint the gradients value\n",
    "    elif transformation == 'blackout':\n",
    "        grads = constraint_black(grads)  # constraint the gradients value\n",
    "\n",
    "    image += grads * step    \n",
    "    pred1, pred2= model.predict(image), q_model.predict(image)\n",
    "    label1, label2 = np.argmax(pred1[0]), np.argmax(pred2[0])\n",
    "    if not label1 == label2:\n",
    "        print(\"different\")\n",
    "        print(label1)\n",
    "        print(label2)\n",
    "        print(tf.keras.applications.resnet.decode_predictions(pred1, top=5)[0])\n",
    "        print(tf.keras.applications.resnet.decode_predictions(pred2, top=5)[0])\n",
    "        gen_img_deprocessed = deprocess_image(image)\n",
    "        orig_img_deprocessed = deprocess_image(orig_img)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1, pred2= model.predict(image), q_model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('n03393912', 'freight_car', 0.546804),\n",
       " ('n04252225', 'snowplow', 0.23667075),\n",
       " ('n04467665', 'trailer_truck', 0.06796761),\n",
       " ('n03417042', 'garbage_truck', 0.051419698),\n",
       " ('n04310018', 'steam_locomotive', 0.017259402)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.applications.resnet.decode_predictions(pred1, top=5)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('n04252225', 'snowplow', 0.6547978),\n",
       " ('n04310018', 'steam_locomotive', 0.07759655),\n",
       " ('n04467665', 'trailer_truck', 0.06391995),\n",
       " ('n03417042', 'garbage_truck', 0.05801411),\n",
       " ('n03393912', 'freight_car', 0.043373536)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.applications.resnet.decode_predictions(pred2, top=5)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.preprocessing.image.array_to_img(gen_image[0,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.preprocessing.image.array_to_img(gen_img_deprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.preprocessing.image.array_to_img(orig_img_deprocessed)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "input_tensor = q_model.get_layer('input_1').input\n",
    "loss1 =  K.mean(model.get_layer('predictions').output[..., orig_label])\n",
    "loss2 =  K.mean(q_model.get_layer('quant_predictions').output[..., orig_label])\n",
    "final_loss = K.mean(loss1 - weight_diff*loss2)\n",
    "grads = normalize(K.gradients(final_loss, input_tensor)[0])\n",
    "iterate = K.function([input_tensor], [grads])\n",
    "\n",
    "#grads = tf.gradients(loss1, input_tensor_1)[0] - weight_diff*tf.gradients(loss2, input_tensor_2)[0]\n",
    "#iterate = K.function([input_tensor_1,input_tensor_2], [grads])\n",
    "orig_img = image.copy()\n",
    "for iters in range(0,grad_iterations):\n",
    "    grads_value = iterate([image])[0]\n",
    "    if transformation == 'light':\n",
    "        grads_value = constraint_light(grads_value)  # constraint the gradients value\n",
    "    elif transformation == 'occl':\n",
    "        grads_value = constraint_occl(grads_value, start_point,occlusion_size)  # constraint the gradients value\n",
    "    elif transformation == 'blackout':\n",
    "        grads_value = constraint_black(grads_value)  # constraint the gradients value\n",
    "\n",
    "    image += grads_value * step    \n",
    "    pred1, pred2= model.predict(image), q_model.predict(image)\n",
    "    label1, label2 = np.argmax(pred1[0]), np.argmax(pred2[0])\n",
    "    if not label1 == label2:\n",
    "        print(\"different\")\n",
    "        print(label1)\n",
    "        print(label2)\n",
    "        print(tf.keras.applications.resnet.decode_predictions(pred1, top=5)[0])\n",
    "        print(tf.keras.applications.resnet.decode_predictions(pred2, top=5)[0])\n",
    "        gen_img_deprocessed = deprocess_image(image)\n",
    "        orig_img_deprocessed = deprocess_image(orig_img)\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

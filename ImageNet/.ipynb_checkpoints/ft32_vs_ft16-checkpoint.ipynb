{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "from tensorflow.python.framework.ops import enable_eager_execution\n",
    "\n",
    "disable_eager_execution()\n",
    "#enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import mixed_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "from tensorflow.keras.layers import Input\n",
    "import imageio\n",
    "\n",
    "from configs import bcolors\n",
    "from utils import *\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  8\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wei.hao/anaconda3/envs/nd_gpu_exp/lib/python3.8/site-packages/tensorflow/python/keras/backend.py:434: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 224, 224\n",
    "with tf.device('/cpu:0'):\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "    K.clear_session()\n",
    "    # define input tensor as a placeholder\n",
    "    input_tensor = Input(shape=[img_rows, img_cols, 3],dtype=tf.float32 )\n",
    "\n",
    "    # load multiple models sharing same input tensor\n",
    "    K.set_learning_phase(0)\n",
    "    model1 = VGG16(input_tensor=input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPUs will likely run quickly with dtype policy mixed_float16 as they all have compute capability of at least 7.0\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "    model2 = VGG16(input_tensor=input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Policy \"mixed_float16\">\n"
     ]
    }
   ],
   "source": [
    "print(model2.dtype_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Policy \"float32\">\n"
     ]
    }
   ],
   "source": [
    "print(model1.dtype_policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ImageNetLabels.txt') as f:\n",
    "    classes = f.readlines()\n",
    "# you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "classes = [x.strip() for x in classes] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def list_pictures(directory, ext='jpg|jpeg|bmp|png|ppm'):\n",
    "    return [os.path.join(root, f)\n",
    "            for root, _, files in os.walk(directory) for f in files\n",
    "            if re.match(r'([\\w]+\\.(?:' + ext + '))', f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation = 'light'\n",
    "start_point = (0, 0)\n",
    "occlusion_size =(50, 50)\n",
    "step = 10\n",
    "grad_iterations = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wei.hao/anaconda3/envs/nd_gpu_exp/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    }
   ],
   "source": [
    "img_paths = list_pictures('./seeds/', ext='JPEG')\n",
    "num_img = 0\n",
    "for img_path in img_paths:\n",
    "    gen_img = preprocess_image(img_path)\n",
    "    orig_img = gen_img.copy()\n",
    "    # first check if input already induces differences\n",
    "    pred1, pred2 = model1.predict(gen_img), model2.predict(gen_img)\n",
    "    label1, label2 = np.argmax(pred1[0]), np.argmax(pred2[0])\n",
    "    \n",
    "    if not label1 == label2:\n",
    "        gen_img_deprocessed = deprocess_image(gen_img)\n",
    "        # save the result to disk\n",
    "        imageio.imwrite('./new_generated_inputs/' + 'already_differ_' + decode_label(pred1) + '_' + decode_label(\n",
    "            pred2) + '.png', gen_img_deprocessed)\n",
    "        continue\n",
    "\n",
    "    # construct joint loss function\n",
    "    orig_label = label1\n",
    "    loss1 = K.mean(model1.get_layer('predictions').output[..., orig_label])\n",
    "    loss2 = -1*K.mean(model2.get_layer('predictions').output[..., orig_label])\n",
    "    layer_output = tf.dtypes.cast(loss1,tf.float16) + loss2\n",
    "    \n",
    "    # for adversarial image generation\n",
    "    final_loss = K.mean(layer_output)\n",
    "\n",
    "    # we compute the gradient of the input picture wrt this loss\n",
    "    grads = normalize(K.gradients(final_loss, input_tensor)[0])\n",
    "\n",
    "    # this function returns the loss and grads given the input picture\n",
    "    iterate = K.function([input_tensor], [loss1, loss2, grads])\n",
    "    \n",
    "    for iters in range(0,grad_iterations):\n",
    "        loss_value1, loss_value2, grads_value = iterate(gen_img)\n",
    "        if transformation == 'light':\n",
    "            grads_value = constraint_light(grads_value)  # constraint the gradients value\n",
    "        elif transformation == 'occl':\n",
    "            grads_value = constraint_occl(grads_value, start_point,occlusion_size)  # constraint the gradients value\n",
    "        elif transformation == 'blackout':\n",
    "            grads_value = constraint_black(grads_value)  # constraint the gradients value\n",
    "\n",
    "        gen_img += grads_value * step\n",
    "        pred1, pred2= model1.predict(gen_img), model2.predict(gen_img)\n",
    "        label1, label2 = np.argmax(pred1[0]), np.argmax(pred2[0])\n",
    "        if not label1 == label2:\n",
    "            num_img += 1\n",
    "            gen_img_deprocessed = deprocess_image(gen_img)\n",
    "            orig_img_deprocessed = deprocess_image(orig_img)\n",
    "            # save the result to disk\n",
    "            imageio.imwrite(\n",
    "                './new_generated_inputs/' + transformation + '_' + decode_label(pred1) + '_' + decode_label(\n",
    "                    pred2) + '.png', gen_img_deprocessed)\n",
    "            imageio.imwrite(\n",
    "                './new_generated_inputs/' + transformation + '_' + decode_label(pred1) + '_' + decode_label(\n",
    "                    pred2) + '_orig.png', orig_img_deprocessed)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = list_pictures('./new_generated_inputs', ext='JPEG')\n",
    "img_list = []\n",
    "for img_path in img_paths:\n",
    "    if 'orig' not in img_path:\n",
    "        gen_img = preprocess_image(img_path)\n",
    "        img_list.append(gen_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_img = img_list[0]\n",
    "pil_img = tf.keras.preprocessing.image.array_to_img(gen_img[0,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "display(pil_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1, pred2 = model1.predict(gen_img), model2.predict(gen_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.applications.vgg16.decode_predictions(pred1, top=5)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.applications.vgg16.decode_predictions(pred2, top=5)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nd_gpu_exp",
   "language": "python",
   "name": "nd_gpu_exp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "from tensorflow.python.framework.ops import enable_eager_execution\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "disable_eager_execution()\n",
    "#enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.zeros((1,224,224,3))\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 224 ,224\n",
    "input_shape = (img_rows, img_cols, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "# define input tensor as a placeholder\n",
    "input_tensor = Input(shape=[img_rows, img_cols, 3],dtype=tf.float32 )\n",
    "model = VGG16(input_tensor=input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 1 \n",
    "loss = model.get_layer('predictions').output[..., label] #prediction score for the first labeled class\n",
    "grads = tf.gradients(loss, input_tensor)[0] #gradient wrt input\n",
    "my_func1 = K.function([input_tensor], [loss,grads])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "l,grads_value = my_func1(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'gradients/block1_conv1/Conv2D_grad/Conv2DBackpropInput:0' shape=(None, 224, 224, 3) dtype=float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-3.0174573e-07, -1.9591373e-07, -6.2357168e-07],\n",
       "         [ 6.3699542e-07,  8.3343809e-07,  6.7949131e-08],\n",
       "         [ 6.3554955e-07,  7.5128139e-07,  1.0226256e-07],\n",
       "         ...,\n",
       "         [ 3.1516376e-07,  8.9249664e-07,  3.0592270e-07],\n",
       "         [-1.9307819e-07,  5.0339560e-07,  4.2625466e-08],\n",
       "         [-3.2156379e-07,  7.4459940e-08, -1.0066536e-07]],\n",
       "\n",
       "        [[ 2.8785877e-07,  4.6422997e-07, -4.9973511e-07],\n",
       "         [ 2.6554696e-06,  2.8442366e-06,  1.1804447e-06],\n",
       "         [ 2.9480657e-06,  2.8692509e-06,  1.3597398e-06],\n",
       "         ...,\n",
       "         [ 1.4962332e-06,  2.3416783e-06,  1.2267468e-06],\n",
       "         [ 1.3002781e-07,  1.1519543e-06,  3.2780386e-07],\n",
       "         [-5.9840772e-07, -3.9379806e-08, -3.2764109e-07]],\n",
       "\n",
       "        [[ 9.9312513e-07,  8.4483196e-07, -7.5169538e-07],\n",
       "         [ 3.4999507e-06,  2.6276255e-06,  5.2366715e-09],\n",
       "         [ 3.4566092e-06,  1.4672722e-06, -8.7326816e-07],\n",
       "         ...,\n",
       "         [ 2.0827724e-06,  1.8509977e-06,  8.5389843e-07],\n",
       "         [ 3.6452101e-07,  6.0457825e-07, -7.2010536e-08],\n",
       "         [-5.9161226e-07, -3.1009642e-07, -5.3446388e-07]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-9.9872079e-07, -2.5560762e-06, -3.2437999e-06],\n",
       "         [-2.0496257e-06, -4.2420138e-06, -6.0345265e-06],\n",
       "         [ 4.7352484e-07, -1.8906412e-06, -4.6706923e-06],\n",
       "         ...,\n",
       "         [ 9.0009155e-07, -1.2548264e-07, -8.0630926e-08],\n",
       "         [ 6.3551653e-07,  7.4958734e-08,  1.7229104e-07],\n",
       "         [ 1.7818837e-07,  2.2253236e-08,  1.0830922e-07]],\n",
       "\n",
       "        [[ 2.6625884e-09, -7.0883641e-07, -1.3163036e-06],\n",
       "         [-1.7089974e-08, -8.8581174e-07, -2.3810101e-06],\n",
       "         [ 1.5909726e-06,  7.2142785e-07, -1.4848526e-06],\n",
       "         ...,\n",
       "         [ 7.6375557e-07,  4.5709078e-07,  3.9345792e-07],\n",
       "         [ 4.7445383e-07,  4.3522655e-07,  4.3694689e-07],\n",
       "         [ 1.2517663e-07,  1.7711488e-07,  2.2443396e-07]],\n",
       "\n",
       "        [[ 2.4114686e-07,  1.2477759e-07, -1.6435455e-07],\n",
       "         [ 1.0052315e-06,  1.0790452e-06,  3.5047896e-07],\n",
       "         [ 1.6997167e-06,  1.8319340e-06,  8.1031703e-07],\n",
       "         ...,\n",
       "         [ 3.5278219e-07,  4.6828154e-07,  3.7145378e-07],\n",
       "         [ 1.7050117e-07,  3.6270927e-07,  3.0871206e-07],\n",
       "         [ 5.9546812e-09,  1.1579590e-07,  1.2331364e-07]]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "# define input tensor as a placeholder\n",
    "input_tensor_2 = Input(shape=[img_rows, img_cols, 3],dtype=tf.float32 )\n",
    "model_2 = VGG16(input_tensor=input_tensor_2)\n",
    "\n",
    "# q_aware stands for for quantization aware.\n",
    "q_model = tfmot.quantization.keras.quantize_model(model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 1 \n",
    "quantized_input = q_model.get_layer('quant_block1_conv1').input\n",
    "loss2 = q_model.get_layer('quant_predictions').output[..., label] #prediction score for the first labeled class\n",
    "grads = tf.gradients(loss2, quantized_input)[0] #gradient wrt input\n",
    "my_func2  = K.function([input_tensor_2], [quantized_input,loss2,grads])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "2 root error(s) found.\n  (0) Invalid argument: You must feed a value for placeholder tensor 'input_1_5' with dtype float and shape [?,224,224,3]\n\t [[{{node input_1_5}}]]\n\t [[quant_predictions/cond_1/then/_892/MovingAvgQuantize/BatchMax/_2661]]\n  (1) Invalid argument: You must feed a value for placeholder tensor 'input_1_5' with dtype float and shape [?,224,224,3]\n\t [[{{node input_1_5}}]]\n0 successful operations.\n0 derived errors ignored.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-dac3dfc084ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrads_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_func2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3822\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3824\u001b[0;31m     fetched = self._callable_fn(*array_vals,\n\u001b[0m\u001b[1;32m   3825\u001b[0m                                 run_metadata=self.run_metadata)\n\u001b[1;32m   3826\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1468\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1469\u001b[0m         \u001b[0mrun_metadata_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1470\u001b[0;31m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0m\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1472\u001b[0m                                                run_metadata_ptr)\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument: You must feed a value for placeholder tensor 'input_1_5' with dtype float and shape [?,224,224,3]\n\t [[{{node input_1_5}}]]\n\t [[quant_predictions/cond_1/then/_892/MovingAvgQuantize/BatchMax/_2661]]\n  (1) Invalid argument: You must feed a value for placeholder tensor 'input_1_5' with dtype float and shape [?,224,224,3]\n\t [[{{node input_1_5}}]]\n0 successful operations.\n0 derived errors ignored."
     ]
    }
   ],
   "source": [
    "_,l,grads_value = my_func2(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

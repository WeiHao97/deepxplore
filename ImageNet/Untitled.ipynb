{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "from tensorflow.python.framework.ops import enable_eager_execution\n",
    "import cv2\n",
    "\n",
    "#disable_eager_execution()\n",
    "enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import mixed_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "from tensorflow.keras.layers import Input\n",
    "import scipy.misc\n",
    "\n",
    "from configs import bcolors\n",
    "from utils import *\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "from tiny_imagenet import TinyImagenetDataset\n",
    "\n",
    "tiny_imagenet_builder = TinyImagenetDataset()\n",
    "\n",
    "# this call (download_and_prepare) will trigger the download of the dataset\n",
    "# and preparation (conversion to tfrecords)\n",
    "#\n",
    "# This will be done only once and on next usage tfds will\n",
    "# use the cached version on your host.\n",
    "#\n",
    "# You can pass optional argument to this method called\n",
    "# DownloadConfig (https://www.tensorflow.org/datasets/api_docs/python/tfds/download/DownloadConfig)\n",
    "# to customize the location where the dataset is downloaded, extracted and processed.\n",
    "tiny_imagenet_builder.download_and_prepare()\n",
    "\n",
    "train_dataset = tiny_imagenet_builder.as_dataset(split=\"train\")\n",
    "validation_dataset = tiny_imagenet_builder.as_dataset(split=\"validation\")\n",
    "\n",
    "assert(isinstance(train_dataset, tf.data.Dataset))\n",
    "assert(isinstance(validation_dataset, tf.data.Dataset))\n",
    "\n",
    "# print info about the data\n",
    "#print(tiny_imagenet_builder.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tiny_imagenet_builder.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = []\n",
    "train_labels = []\n",
    "ds_numpy = tfds.as_numpy(train_dataset)\n",
    "for item in ds_numpy:\n",
    "    image, label, id = item[\"image\"], item[\"label\"], item[\"id\"]\n",
    "    train_images.append(keras.applications.vgg16.preprocess_input(cv2.resize(image, (224,224), interpolation = cv2.INTER_AREA)))\n",
    "    train_labels.append(label)\n",
    "    break\n",
    "    \n",
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = []\n",
    "test_labels = []\n",
    "ds_numpy = tfds.as_numpy(validation_dataset)\n",
    "for item in ds_numpy:\n",
    "    image, label, id = item[\"image\"], item[\"label\"], item[\"id\"]\n",
    "    test_images.append(np.expand_dims(keras.applications.vgg16.preprocess_input(image),axis=0))\n",
    "    test_labels.append(label)\n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels  = tf.keras.utils.to_categorical(train_labels , num_classes=200)\n",
    "train_labels  = tf.keras.utils.to_categorical(train_labels , num_classes=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 224 ,224\n",
    "input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "K.clear_session()\n",
    "# define input tensor as a placeholder\n",
    "input_tensor_1 = Input(shape=[img_rows, img_cols, 3],dtype=tf.float32 )\n",
    "input_tensor_2 = Input(shape=[img_rows, img_cols, 3])\n",
    "\n",
    "# load multiple models sharing same input tensor\n",
    "K.set_learning_phase(0)\n",
    "model1 = VGG16(input_tensor=input_tensor_1)\n",
    "model2 = VGG16(input_tensor=input_tensor_2)\n",
    "\n",
    "quantize_model = tfmot.quantization.keras.quantize_model\n",
    "\n",
    "# q_aware stands for for quantization aware.\n",
    "model2 = quantize_model(model2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# load multiple models sharing same input tensor\n",
    "K.set_learning_phase(0)\n",
    "resnet_v2_101 = tf.keras.Sequential([\n",
    "  keras.layers.InputLayer(input_shape=(224, 224, 3)),\n",
    "  hub.KerasLayer(\"https://tfhub.dev/google/imagenet/resnet_v2_101/classification/4\")\n",
    "])\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(resnet_v2_101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load All Images (1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def list_pictures(directory, ext='jpg|jpeg|bmp|png|ppm'):\n",
    "    return [os.path.join(root, f)\n",
    "            for root, _, files in os.walk(directory) for f in files\n",
    "            if re.match(r'([\\w]+\\.(?:' + ext + '))', f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = list_pictures('./seeds/', ext='JPEG')\n",
    "target_images = []\n",
    "for img_path in img_paths:\n",
    "    gen_img = preprocess_image(img_path)\n",
    "    orig_img = gen_img.copy()\n",
    "    # first check if input already induces differences\n",
    "    pred1, pred2 = model1.predict(gen_img), model2.predict(gen_img)\n",
    "    label1, label2 = np.argmax(pred1[0]), np.argmax(pred2[0])\n",
    "    if label1 == label2:\n",
    "        target_images.append(orig_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(target_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./test_images.npy', 'wb') as f:\n",
    "    np.save(f, target_images[0])\n",
    "    np.save(f, target_images[1])\n",
    "    np.save(f, target_images[2])\n",
    "    np.save(f, target_images[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Images with Same Label (4?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ImageNetLabels.txt') as f:\n",
    "    classes = f.readlines()\n",
    "# you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "classes = [x.strip() for x in classes] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_images = []\n",
    "with open('test_images.npy', 'rb') as f:\n",
    "    target_images.append(np.load(f, encoding='bytes',allow_pickle=True))\n",
    "    target_images.append(np.load(f, encoding='bytes',allow_pickle=True))\n",
    "    target_images.append(np.load(f, encoding='bytes',allow_pickle=True))\n",
    "    target_images.append(np.load(f, encoding='bytes',allow_pickle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(target_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_img = target_images[1]\n",
    "pil_img = tf.keras.preprocessing.image.array_to_img(gen_img[0,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "display(pil_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1, pred2 = model1.predict(gen_img), model2.predict(gen_img)\n",
    "label1, label2 = np.argmax(pred1[0]), np.argmax(pred2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.applications.resnet.decode_predictions(pred1, top=5)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.applications.resnet.decode_predictions(pred2, top=5)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_diff = 1\n",
    "orig_label = label1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_input = model2.get_layer('input_2').input\n",
    "loss2 = K.mean(model2.get_layer('quant_predictions').output[..., orig_label])\n",
    "grads =tf.gradients(loss2, quantized_input)[0]\n",
    "iterate = K.function([input_tensor_2], [grads])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = model1.get_layer('input_1').input\n",
    "loss1 = K.mean(model1.get_layer('predictions').output[..., orig_label])\n",
    "grads = tf.gradients(loss1, input_tensor_1)[0]\n",
    "iterate = K.function([input_tensor_1], [grads])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads_value = iterate(gen_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = model1.get_layer('input_1').input\n",
    "loss1 = K.mean(model1.get_layer('predictions').output[..., orig_label])\n",
    "grads = tf.gradients(loss1, input_)[0]\n",
    "iterate = K.function([input_tensor_1], [grads])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads_value = iterate(gen_img.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss1 = K.mean(model1.get_layer('predictions').output[..., orig_label])\n",
    "loss2 = K.mean(model2.get_layer('quant_predictions').output[..., orig_label])\n",
    "quantized_input = model2.get_layer('quant_block1_conv1').input\n",
    "\n",
    "# we compute the gradient of the input picture wrt this loss\n",
    "grads = normalize(tf.gradients(loss1, input_tensor)[0] - tf.gradients(loss2, quantized_input)[0])\n",
    "\n",
    "# this function returns the loss and grads given the input picture\n",
    "iterate = K.function([input_tensor], [grads])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation = 'light'\n",
    "start_point = (0, 0)\n",
    "occlusion_size =(50, 50)\n",
    "step = 10\n",
    "grad_iterations = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_img = gen_img.copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.get_layer('quantize_layer').output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.get_layer('input_1').output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.get_layer('input_1').output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function returns the loss and grads given the input picture\n",
    "layer1 = tf.quantization.fake_quant_with_min_max_vars(\n",
    "    input_tensor, -123.68000030517578,151.06100463867188, num_bits=8\n",
    ")\n",
    "lll = K.function([input_tensor], [layer1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we run gradient ascent for 20 steps\n",
    "for iters in range(0,grad_iterations):\n",
    "    \n",
    "    loss_value1, grads_value = iterate(gen_img.astype(float))\n",
    "    if transformation == 'light':\n",
    "        grads_value = constraint_light(grads_value)  # constraint the gradients value\n",
    "    elif transformation == 'occl':\n",
    "        grads_value = constraint_occl(grads_value, start_point,occlusion_size)  # constraint the gradients value\n",
    "    elif transformation == 'blackout':\n",
    "        grads_value = constraint_black(grads_value)  # constraint the gradients value\n",
    "\n",
    "    gen_img += grads_value * step\n",
    "    pred1, pred2= model1.predict(gen_img), model2.predict(gen_img)\n",
    "    label1, label2 = np.argmax(pred1[0]), np.argmax(pred2[0])\n",
    "    if not label1 == label2:\n",
    "        gen_img_deprocessed = deprocess_image(gen_img)\n",
    "        orig_img_deprocessed = deprocess_image(orig_img)\n",
    "        print(\"yeah\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_img - gen_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
